{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "    Notebook version: 1.0 (Oct 26, 2015)\n",
    "\n",
    "    Author: Jes√∫s Cid Sueiro (jcid@tsc.uc3m.es)\n",
    "\n",
    "    Changes: v.1.0 - First version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To visualize plots in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Imported libraries\n",
    "#import csv\n",
    "#import random\n",
    "#import matplotlib\n",
    "#import matplotlib.pyplot as plt\n",
    "#import pylab\n",
    "\n",
    "#import numpy as np\n",
    "#from mpl_toolkits.mplot3d import Axes3D\n",
    "#from sklearn.preprocessing import PolynomialFeatures\n",
    "#from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection.\n",
    "\n",
    "The advantages of support vector machines are:\n",
    "\n",
    "- Effective in high dimensional spaces.\n",
    "- Still effective in cases where number of dimensions is greater than the number of samples.\n",
    "- Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.\n",
    "- Versatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.\n",
    "\n",
    "The disadvantages of support vector machines include:\n",
    "\n",
    "- If the number of features is much greater than the number of samples, the method is likely to give poor performances.\n",
    "- SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation (see Scores and probabilities, below).\n",
    "- The support vector machines in scikit-learn support both dense (numpy.ndarray and convertible to that by numpy.asarray) and sparse (any scipy.sparse) sample vectors as input. However, to use an SVM to make predictions for sparse data, it must have been fit on such data. For optimal performance, use C-ordered numpy.ndarray (dense) or scipy.sparse.csr_matrix (sparse) with dtype=float64.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM implementations in Scikit Learn\n",
    "\n",
    "SVC, NuSVC and LinearSVC are classes capable of performing multi-class classification on a dataset.\n",
    "\n",
    "SVC and NuSVC are similar methods, but accept slightly different sets of parameters and have different mathematical formulations (see section Mathematical formulation). On the other hand, LinearSVC is another implementation of Support Vector Classification for the case of a linear kernel. Note that LinearSVC does not accept keyword kernel, as this is assumed to be linear. It also lacks some of the members of SVC and NuSVC, like support_.\n",
    "As other classifiers, SVC, NuSVC and LinearSVC take as input two arrays: an array X of size [n_samples, n_features] holding the training samples, and an array y of class labels (strings or integers), size [n_samples]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [0, 1]\n",
    "clf = svm.SVC()\n",
    "clf.fit(X, y)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After being fitted, the model can then be used to predict new values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[2., 2.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVMs decision function depends on some subset of the training data, called the support vectors. Some properties of these support vectors can be found in members support_vectors_, support_ and n_support:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.]\n",
      " [ 1.  1.]]\n",
      "[0 1]\n",
      "[1 1]\n"
     ]
    }
   ],
   "source": [
    "# get support vectors\n",
    "print clf.support_vectors_\n",
    "# get indices of support vectors\n",
    "print clf.support_ \n",
    "# get number of support vectors for each class\n",
    "print clf.n_support_ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Example: Iris Dataset.\n",
    "\n",
    "As an illustration, consider the <a href = http://archive.ics.uci.edu/ml/datasets/Iris> Iris dataset </a>, taken from the <a href=http://archive.ics.uci.edu/ml/> UCI Machine Learning repository</a>. This data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant (*setosa*, *versicolor* or *virginica*). Each instance contains 4 measurements of given flowers: sepal length, sepal width, petal length and petal width, all in centimeters. \n",
    "\n",
    "We will try to fit the logistic regression model to discriminate between two classes using only two attributes.\n",
    "\n",
    "First, we load the dataset and split them in training and test subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 93\n",
      "Test: 57\n"
     ]
    }
   ],
   "source": [
    "# Adapted from a notebook by Jason Brownlee\n",
    "def loadDataset(filename, split):\n",
    "    xTrain = []\n",
    "    cTrain = []\n",
    "    xTest = []\n",
    "    cTest = []\n",
    "\n",
    "    with open(filename, 'rb') as csvfile:\n",
    "        lines = csv.reader(csvfile)\n",
    "        dataset = list(lines)\n",
    "    for i in range(len(dataset)-1):\n",
    "        for y in range(4):\n",
    "            dataset[i][y] = float(dataset[i][y])\n",
    "        item = dataset[i]\n",
    "        if random.random() < split:\n",
    "            xTrain.append(item[0:4])\n",
    "            cTrain.append(item[4])\n",
    "        else:\n",
    "            xTest.append(item[0:4])\n",
    "            cTest.append(item[4])\n",
    "    return xTrain, cTrain, xTest, cTest\n",
    "\n",
    "with open('iris.data', 'rb') as csvfile:\n",
    "    lines = csv.reader(csvfile)\n",
    "\n",
    "xTrain_all, cTrain_all, xTest_all, cTest_all = loadDataset('iris.data', 0.66)\n",
    "nTrain_all = len(xTrain_all)\n",
    "nTest_all = len(xTest_all)\n",
    "print 'Train: ' + str(nTrain_all)\n",
    "print 'Test: ' + str(nTest_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we select two classes and two attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select attributes\n",
    "i = 0 # Try 0,1,2,3\n",
    "j = 1 # Try 0,1,2,3 with j!=i\n",
    "\n",
    "# Select two classes\n",
    "c0 = 'Iris-versicolor' \n",
    "c1 = 'Iris-virginica'\n",
    "\n",
    "# Select two coordinates\n",
    "ind = [i, j]\n",
    "\n",
    "# Take training test\n",
    "X_tr = np.array([[xTrain_all[n][i] for i in ind] for n in range(nTrain_all) \n",
    "                  if cTrain_all[n]==c0 or cTrain_all[n]==c1])\n",
    "C_tr = [cTrain_all[n] for n in range(nTrain_all) \n",
    "          if cTrain_all[n]==c0 or cTrain_all[n]==c1]\n",
    "Y_tr = np.array([int(c==c1) for c in C_tr])\n",
    "n_tr = len(X_tr)\n",
    "\n",
    "# Take test set\n",
    "X_tst = np.array([[xTest_all[n][i] for i in ind] for n in range(nTest_all) \n",
    "                 if cTest_all[n]==c0 or cTest_all[n]==c1])\n",
    "C_tst = [cTest_all[n] for n in range(nTest_all) \n",
    "         if cTest_all[n]==c0 or cTest_all[n]==c1]\n",
    "Y_tst = np.array([int(c==c1) for c in C_tst])\n",
    "n_tst = len(X_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2. Data normalization\n",
    "\n",
    "Normalization of data is a common pre-processing step in many machine learning algorithms. Its goal is to get a dataset where all input coordinates have a similar scale. Learning algorithms usually show less instabilities and convergence problems when data are normalized.\n",
    "\n",
    "We will define a normalization function that returns a training data matrix with zero sample mean and unit sample variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(X, mx=None, sx=None):\n",
    "    \n",
    "    # Compute means and standard deviations\n",
    "    if mx is None:\n",
    "        mx = np.mean(X, axis=0)\n",
    "    if sx is None:\n",
    "        sx = np.std(X, axis=0)\n",
    "\n",
    "    # Normalize\n",
    "    X0 = (X-mx)/sx\n",
    "\n",
    "    return X0, mx, sx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can normalize training and test data. Observe in the code that the same transformation should be applied to training and test data. This is the reason why normalization with the test data is done using the means and the variances computed with the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "Xn_tr, mx, sx = normalize(X_tr)\n",
    "Xn_tst, mx, sx = normalize(X_tst, mx, sx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure generates a plot of the normalized training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.0, 3.0, -3.0, 3.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAERCAYAAAB8eMxzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nABAxBD8ARAzBDwAR8/8BmYQiUipn6PcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107f1ddd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Separate components of x into different arrays (just for the plots)\n",
    "x0c0 = [Xn_tr[n][0] for n in range(n_tr) if Y_tr[n]==0]\n",
    "x1c0 = [Xn_tr[n][1] for n in range(n_tr) if Y_tr[n]==0]\n",
    "x0c1 = [Xn_tr[n][0] for n in range(n_tr) if Y_tr[n]==1]\n",
    "x1c1 = [Xn_tr[n][1] for n in range(n_tr) if Y_tr[n]==1]\n",
    "\n",
    "# Scatterplot.\n",
    "labels = {'Iris-setosa': 'Setosa', \n",
    "          'Iris-versicolor': 'Versicolor',\n",
    "          'Iris-virginica': 'Virginica'}\n",
    "plt.plot(x0c0, x1c0,'r.', label=labels[c0])\n",
    "plt.plot(x0c1, x1c1,'g+', label=labels[c1])\n",
    "plt.xlabel('$x_' + str(ind[0]) + '$')\n",
    "plt.ylabel('$x_' + str(ind[1]) + '$')\n",
    "plt.legend(loc='best')\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to apply the gradient descent rule, we need to define two methods: \n",
    " - A `fit` method, that receives the training data and returns the model weights and the value of the negative log-likelihood during all iterations.\n",
    " - A `predict` method, that receives the model weight and a set of inputs, and returns the posterior class probabilities for that input, as well as their corresponding class predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def logregFit(Z_tr, Y_tr, rho, n_it):\n",
    "\n",
    "    # Data dimension\n",
    "    n_dim = Z_tr.shape[1]\n",
    "\n",
    "    # Initialize variables\n",
    "    nll_tr = np.zeros(n_it)\n",
    "    pe_tr = np.zeros(n_it)\n",
    "    w = np.random.randn(n_dim,1)\n",
    "\n",
    "    # Running the gradient descent algorithm\n",
    "    for n in range(n_it):\n",
    "        \n",
    "        # Compute posterior probabilities for weight w\n",
    "        p1_tr = logistic(np.dot(Z_tr, w))\n",
    "        p0_tr = logistic(-np.dot(Z_tr, w))\n",
    "\n",
    "        # Compute negative log-likelihood\n",
    "        nll_tr[n] = - np.dot(Y_tr.T, np.log(p1_tr)) - np.dot((1-Y_tr).T, np.log(p0_tr))\n",
    "\n",
    "        # Update weights\n",
    "        w += rho*np.dot(Z_tr.T, Y_tr - p1_tr)\n",
    "\n",
    "    return w, nll_tr\n",
    "\n",
    "def logregPredict(Z, w):\n",
    "\n",
    "    # Compute posterior probability of class 1 for weights w.\n",
    "    p = logistic(np.dot(Z, w))\n",
    "    \n",
    "    # Class\n",
    "    D = [int(round(pn)) for pn in p]\n",
    "    \n",
    "    return p, D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the behavior of the gradient descent method by fitting a logistic regression model with ${\\bf z}({\\bf x}) = (1, {\\bf x}^\\intercal)^\\intercal$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal weights are:\n",
      "[[-0.03785205]\n",
      " [ 1.1542709 ]\n",
      " [ 0.48717643]]\n",
      "The final error rates are:\n",
      "- Training: 0.230769230769\n",
      "- Test: 0.371428571429\n",
      "The NLL after training is 34.2132457772\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEPCAYAAABCyrPIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAG2BJREFUeJzt3X2UVdWZ5/HvT15SvIhlBUR8Q3xro4nCRI0t2Ja22oIv\nHe3B1pgxy64RsxKNcXWMxlmORXfSiXYwZma6XWEkRk0bxcnSqGkRjBaJSSZoAortC+lpkagIRkAp\nURF55o9zrlyKulXnXu65L1W/z1q16p5d95z9cLzWU3vvs/dWRGBmZrZLvQMwM7PG4IRgZmaAE4KZ\nmaWcEMzMDHBCMDOzlBOCmZkBNUgIklZKelrSUklL0rJOSS+nZUslnZZ3HGZm1rehNagjgPaIWNej\n7MaIuLEG9ZuZWQa16jJSxjIzM6uTWiSEAB6R9KSki4vKL5P0lKR5klprEIeZmfVBeS9dIWlCRKyW\nNA5YBFwGvAC8nr7l74EJEdGRayBmZtan3BPCdpVJ1wHdETGnqGx/4IGI+ESP93qRJTOzCkRERV3y\nuXYZSRopadf09SjgVGC5pD2L3nY2sLy386dPD9avDyL8tTNf1113Xd1jGEhfvp++n438tTPyHkMY\nD/xC0jLgN8CDEbEQuCF9FPUp4ATgit5OfughmDUr5wjNzAzI+bHTiHgRmNxL+YVZzj/qKJg7t+ph\nmZlZLxp6pvKiRdDq5492Wnt7e71DGFB8P6vL97Nx1HRQuRySolFjMzNrVJKICgeVazFT2cysbJLn\nrvan2n80OyGYWcNyL0FpeSTMhh5DMDOz2nFCMDMzwAnBzMxSTghmZnU0Y8YM7rjjjnqHAfixUzNr\nUOnjk/UOo1ejR4/+cFD37bffpqWlhSFDhgAwd+5czj///NxjKHV/duaxUycEM2tIjZwQik2aNIl5\n8+Zx0kkn7fCzLVu2MHRoPg9z5pEQ3GVkZlYlXV1d7LPPPtxwww1MmDCBjo4ONmzYwBlnnMEee+xB\nW1sbZ555Jq+88sqH57S3tzNv3jwAfvCDHzBt2jSuvPJK2traOOCAA1iwYEHN4ndCMLOmNGsWtLfD\njBmwYUPtzy9lzZo1rF+/nlWrVvG9732PrVu30tHRwapVq1i1ahUjRozg0ksv/fD9krabU7BkyRIO\nPfRQ3njjDb761a/S0VG7rWKcEMysKa1YAYsXb78qcmdn8lXQ13Fv51fDLrvswuzZsxk2bBgtLS20\ntbVx9tln09LSwujRo7nmmmtYvHhxyfMnTpxIR0cHkrjwwgtZvXo1a9eurV6AffBMZTNrSiNHJt+L\nV0Uu/uXf33Fv51fDuHHjGD58+IfHmzZt4oorruDhhx9m/fr1AHR3dxMRvc423nPPbdvFjEyD7O7u\nZo899qhekCW4hWBmTenOO2HmzMpXRd7Z80vp+Ut+zpw5rFixgiVLlvDmm2+yePHiqmxmkwe3EMys\nKbW2wvz59Ts/q+7ubkaMGMFuu+3GunXrmD17dv6VVsgtBDOzKurZQvjyl7/MO++8w9ixYznuuOOY\nPn16yYXpeg4w93a9PHkegpk1pGaZh1AvnodgZma5cUIwMzPACcHMzFJOCGZmBjghmJlZygnBzMwA\nT0wzswZWy2fwzQnBzBqU5yDUnruMzMwMcEIwM7OUE4KZmQFOCGZmlnJCMDMzwAnBzMxSTghmZgY4\nIZiZWcoJwczMACcEMzNL5b50haSVwFvAB8D7EXGMpDbgbmAisBI4NyI25B2LmZmVVosWQgDtETEl\nIo5Jy64GFkXEIcDP0mMzM6ujWnUZ9Vyy8CzgtvT1bcCnaxSHmZmVUKsWwiOSnpR0cVo2PiLWpK/X\nAONrEIeZmfWhFstfT42I1ZLGAYskPV/8w4gISb2uc9vZ2fnh6/b2dtrb2/OM08ys6XR1ddHV1VWV\na6mWa45Lug7oBi4mGVd4TdIE4LGIOLTHe8ProZuZlUcSEVHRzkK5dhlJGilp1/T1KOBUYDlwP/C5\n9G2fA+7LMw4zM+tfri0ESZOAe9PDocC/RMQ308dO5wP7UeKxU7cQzMzKtzMthJp2GZXDCcHMrHwN\n22VkZmbNwwnBzMwAJwQzM0s5IZiZGdDHxDRJy/s4LyLiiBziMTOzOulrpvKZ6fcvpN/vIFmT6IJc\nIzIzs7ro97FTScsiYnKPsqURMSXXwPzYqZlZ2fJ+7FSSphUdTGXH1UvNzKzJZVnc7m+AWyXtlh5v\nAC7KLyQzM6uHzDOVCwkhIt7MNaJt9cXmzcGwYbWozcxsYMi1y0hSq6TvAI8Cj0qaU9RaMDOzASLL\nGML3SfZEngmcC2wEbs0zqAK3DszMaifLU0ZPRcSR/ZVVPTA/ZWRmVra8nzJ6R9LxRZVNAzZVUlm5\nNm6sRS1mZgbZnjL6PHB70bjBerZtbpOrXbywhplZzZTzlNEYgIh4K9eIttXnLiMzszLV6imjx4DH\n/JSRmdnA1NBPGb3+ei1qMTMzaPCnjNatC3bfPc9azMwGlgH7lJGTgZlZ7TT0U0ZmZlY7Df2U0apV\nwb771qI2M7OBYWe6jPptIUhqAf4K2B8YIkkkO6b9XSUVlmP48LxrMDOzgixdRj8hWfL6t8C7+Yaz\nvfHja1mbmdngliUh7B0Rf5F7JGZmVldZnjL6laQjco+kF7//fT1qNTMbnEq2ECQtT18OAS6S9CLw\nXloWEZF7kvjIR/KuwczMCko+ZSRp/75OjIiV1Q9nu/q9lpGZWZnyespoXUS8JamtwrjMzKyJ9NVC\n+GlEnC5pJbDDmyJiUq6BSbF8efDxj+dZi5nZwJJLCyEiTk+/719hXDutpaVeNZuZDT59tRD+U18n\nRsTvcoloW/0eQzAzK9POtBD6Sghd9NJVVBARJ1ZSYVZOCGZm5cslIdSbpHjiieCoo+odiZlZ88h7\nx7RRkq6V9L/T44MlnVFJZeUaObIWtZiZGWSbqXwrsBk4Lj1+FfhG1gokDZG0VNID6XGnpJfTsqWS\nTit17mGHZa3FzMx2VpaEcGBEXE+SFIiIt8us43LgWbaNRwRwY0RMSb8WlHk9MzPLQZaE8J6kEYUD\nSQeybQmLPknaB5gB3AIU+rRU9LpPjz+e5V1mZlYNWRJCJ7AA2EfSncCjwFUZr/8d4Epga1FZAJdJ\nekrSPEmtpU4ePTpjLWZmttOyJITfkmyQcxFwJ3AUsLK/k9KB57URsZTtWwQ3A5OAycBqYE6pa0ye\nnCE6MzOriiz7ITwATI+IBwEkHQbcAxzez3nHAWdJmgG0AGMk3R4RFxbeIOmW9Pq96uzs/PB1e3s7\n7e3tGcI1Mxs8urq66Orqqsq1+p2HIOl0ki6iGcCfALcDF0TEssyVSCcAX4mIMyVNiIjVafkVwNER\n8ZlezolFi4KTT87+jzEzG+xy3VM5In4qaTiwCBgNnBMRL5QbI9ueMrpB0pHp8YvAJaVO2nXXMmsx\nM7OK9bV0xf/sUXQS8P+Al0g2yPlSroF56Qozs7Ll1UL4Lclf8erl2L+pzcwGmIZey+jBB4PTT693\nJGZmzSOXFoKkeyJiZtHeysVqsqfymDF512BmZgV9jSHsFRGvlthbOSLipVwD8xiCmVnZar78taRf\nRsTUSiosow4nBDOzMuW6/HUJ+1V4Xll+/ONa1GJmZlB5QqiJ1pKrHJmZWbX1NYbwV2z/2ClFx9+L\niLG5BuYuIzOzsuU1D+FMSs83KLn+kJmZNaeGnofwwx8GF1xQ70jMzJpHzQaVJT1YSSWVamurZW1m\nZoNbWS0ESUsjYkqO8RTX5TEEM7My1fKx08xLXpuZWXMpKyFExEV5BdKbefNqWZuZ2eDW734I6VpG\nPR8/fRN4Avh6RLyRU2yMzfXBVjMzK5Zlx7R/BLaQ7Kcs4DxgJPAaMDUizswlMI8hmJmVLdcd04CT\newwkP10YXC6xEqqZmTWhLGMIQyR9qnAg6Zii87bkElXqn/4pz6ubmVmxLC2EDuBWSaPT441Ah6RR\nwDdziwwYNy7Pq5uZWbHM8xAk7QYQEW/mGtG2+jyGYGZWplznIUhqlfQd4FHgUUlzCsnBzMwGjixj\nCN8H3gJmAueSdBndmmdQBXPm1KIWMzODbGMIB0bEOUXHnZKeyiugYuPH16IWMzODbC2EdyQdXziQ\nNA3YlF9I23z2s7WoxczMIFsL4fPA7UXjBuuBz+UXkpmZ1UO/LYSIWBYRRwBHAEdExGTgxNwjA77x\njVrUYmZmUMbidhHxZtEjp3+bUzzbmTChFrWYmRlUuGOapD9ExL45xFNch+chmJmVqZb7IZiZ2QBV\nMiFI6pa0sbcvYK9aBHfttbWoxczMoI+njCJidKmf1cree9c7AjOzwaOhu4zuugtmzIANG+odiZnZ\nwFfRoHItSIpkozaYORPmz69zQGZmTWBnBpUbPiF88pPwyCPQ2lrviMzMGl/uTxlJ2l/SyenrkZLG\nVFJZuaZMgX/9VycDM7NayLKn8izgYqAtIg6UdAhwc0T8ea6BeR6CmVnZ8m4hfBGYRrIENhGxAtij\njOCGSFoq6YH0uE3SIkkrJC2U5L//zcwaQJaE8F5EvFc4kDSUwmhvNpcDzxadczWwKCIOAX6WHvfq\nppvgxRfLqMnMzCqWJSEslvTfgJGSTgHuAR7IcnFJ+wAzgFuAQhPmLOC29PVtwKdLnT9hAgwfnqUm\nMzPbWVnGEHYB/itwalr0MHBLlg5+SfcA/wCMAb4SEWdKWh8Ru6c/F7CucNzjXI8hmJmVaWfGELLs\nh/Bp4LaImFtmUGcAayNiqaT23t4TEZE8XmpmZvWWJSGcBdwkaTFwN7AgIrZkOO844CxJM4AWYIyk\nO4A1kvaMiNckTQDWlrrAzJmdjB4NEydCe3s77e3tGao1Mxs8urq66Orqqsq1Mk1MkzQcmA6cCxxP\nMijckbkS6QS2dRndALwREddLuhpojYgdBpYlxaOPBm1tcOSRWWsyMxvcajJTOU0KfwH8DfBnEfHR\nMgI8AfjbiDhLUhswH9gPWAmcGxE7rFbkMQQzs/LlmhDSLp9zSbbN7CLpNlqYsduoYk4IZmblyzsh\n3AXcRTJ28G4llVRCUjz+eLBqFZx/fq1qNTNrbrk+ZRQR51Vy4WrYbTcYP75etZuZDS4lWwiSfhkR\nUyV1s+PM5IiIXBe4c5eRmVn5Buzy140am5lZo8p1cbt07kC/ZXlYuRK+/e1a1GRmZlnWMvp48UG6\nuN0n8wlneyNGwH771aImMzPrawzhGuBrwAjgnaIfvQ/M7W0yWVUDc5eRmVnZ8n7s9Ft5//IvUa8T\ngplZmXIfVJa0O3AwyZpEAETEzyupMCtJ8d57wZVXwne/m2dNZmYDR67zECRdDHwJ2BdYChwL/Bo4\nqZIKyzF0KBxySN61mJkZZOsyegY4Gvh1REyWdCjwzYg4O9fA3GVkZla2vPdUfjci3kkraomI54E/\nqaQyMzNrXFkSwh/SMYT7gEWS7idZpbQmZs+G116rVW1mZoNXlrWMCl1DnZK6SLbDXJBnUMUOOcT7\nKpuZ1UKWMYS2Xoo3RsT7+YT0Yb0eQzAzK1PeYwi/A/4I/D79+iPwkqTfSarJjGUzM8tfloSwCJge\nER9Nd0k7DXgQ+CJwc57BAcybB088kXctZmaWJSH8aUQ8XDiIiIVp2a+B3Hv399sPWlvzrsXMzPod\nVAZWS7qKZNc0kWynuUbSEGBrnsEBnHJK3jWYmRlkayF8hmSW8n3AvcB+wPnAEJLkYGZmA0DmDXIk\njYqIt3OOp7i+iAgWLIBNm+Ccc2pVs5lZ88p7g5zjJD0LPJ8eHynpnyuprBLjx8Nee9WqNjOzwSvL\nPIQlwH8GfhIRU9Kyf4uIw3MNLG0hzJoFK1bAyJFw550eYDYz60ve8xCIiFU9irZUUlklVqyAxYvh\noYdg1qxa1WpmNvhkecpolaSpAJKGkyyF/VyuURUZNiz5ftRRMHdurWo1Mxt8snQZjQO+C5xM8tjp\nQuBLEfFGroGlXUavvw6nnw4LF7q7yMysP7nvmFYPXsvIzKx8ueyYJum6Ej8KgIj4u0oqNDOzxtTX\noPLbQHePrwA6gKvyD22bO+6An/60ljWamQ0+JVsIEfHtwmtJY0gGky8iWcJiTv6hbXP44TBqVC1r\nNDMbfPocQ5D0UeAK4ALgduCmiFhfk8A8hmBmVra8xhC+DZwNzAWOiIiNFcZnZmZNoGQLQdJWYDPQ\n285oERFjcg2sqIWwaRN0dMCPfpRnjWZmzS+XFkJEZJrFXAsjRsB550EEqKJ/ppmZ9adhfun3RUqe\nMjrxRJgxAzZsqHdEZmYDT1MkBPCaRmZmecs1IUhqkfQbScskPSOpMy3vlPSypKXp12n9XWvz5uS7\n1zQyM8tH7ktXSBoZEZskDQUeBy4HTgM2RsSNfZy33WOnL70El1wCd93lNY3MzErJZVC5WiJiU/py\nODCMdOkLkoXyMps4ERYsqGZkZmZWLPcxBEm7SFoGrAEWRsSS9EeXSXpK0jxJmf/m37o1lzDNzAa9\nWrQQtgKTJe0G3CvpcOBmoLA43t+TLIXR0fPczs7OD1+3t7czd247DzwAxx/v3dPMzAC6urro6uqq\nyrVquvy1pGuBTRExp6hsf+CBiPhEj/fusHTFCSfAz3+evJ45E+bPzzlgM7Mmk/sWmpWSNLbQHSRp\nBHAK8JykPYvedjawPMv1Cgvc+UkjM7Pqy7WFIOkTwG3AEJLkc3dEfF3S7cBkkgHmF4FLImJNj3N3\naCFs2JDMQRgyBH71Kzj0ULj7bncdmZkVDLod04q7jsaOhaOP9piCmRk0cJdRXgpdR6NHwx//mMxe\n3nNPmDbNS1uYmVWqKVsIha6j9evhkUd2/HlLC4wZk6yBtHlz8qjqQQfBmjXw/vvQ3Z0kk4MOSia8\nbUwX9h41CiZNghdeSI4/+CBZWG/33WHduuQ6mzcnXVaTJsHq1cn13n47ud6BBybX6+5OFuIrXG/F\niuS4cL22tuR6H3yw7XoHHACvvlr6egAjR267HsCWLdmut2lTEktf15s0qbz3V7v+ZrzepEkD699T\ni+tNnDiw/j21uF5ra/b3jxkDDz00yLqMCjZsgI99DF57LbkRb72V/CIt/AcxMxt8BlmXUUFrKzz3\nXPII6tNPJ9+PPTb52Zii3Rp23dVlWcrqXX8zltW7/mYsq3f9zViW9f1HHcVOGVI8+auRzJ49uzNL\nbC0tSSJobU2+n3UW/Md/wL33wosvJi2I+++HV15xWV9l9a6/GcvqXX8zltW7/mYsK+f999wD118/\nm87OztmV/N5t6i4jMzPb3qB7ysjMzKrPCcHMzAAnBDMzSzkhmJkZ4IRgZmYpJwQzMwOcEMzMLOWE\nYGZmgBOCmZmlnBDMzAxwQjAzs5QTgpmZAU4IZmaWckIwMzPACcHMzFJOCGZmBjghmJlZygnBzMwA\nJwQzM0s5IZiZGeCEYGZmKScEMzMDnBDMzCzlhGBmZoATgpmZpZwQzMwMcEIwM7OUE4KZmQFOCGZm\nlsotIUhqkfQbScskPSOpMy1vk7RI0gpJCyW15hWDmZlll1tCiIh3gRMjYjIwGThN0qeAq4FFEXEI\n8LP02HLU1dVV7xAGFN/P6vL9bBy5dhlFxKb05XBgGBDAWcBtafltwKfzjMH8P1y1+X5Wl+9n48g1\nIUjaRdIyYA2wMCKWAOMjYk36ljXA+DxjMDOzbPJuIWxNu4z2AT4l6eM9fh4krQYzM6szJb+Ta1CR\ndC2wCbgYaI+I1yRNAB6LiEN7eb8ThZlZBSJClZw3tNqBFEgaC2yJiA2SRgCnAN8C7gc+B1yffr+v\nt/Mr/QeZmVllcmshSPoEyaDxEJKuqbsj4uuS2oD5wH7ASuDciNiQSxBmZpZZzbqMzMyssTXcTGVJ\np0l6XtLvJV1V73iakaSVkp6WtFTSkrTMEwIzkvR9SWskLS8qK3n/JH0t/bw+L+nU+kTdmErcy05J\nL6efz6WSphf9zPeyD5L2lfSYpH9LJ/x+KS2vyuezoRKCpCHA/wJOAw4Dzpf0sfpG1ZSCZOB+SkQc\nk5Z5QmB2t5J8Bov1ev8kHQb8Ncnn9TTgnyU11P9XddbbvQzgxvTzOSUiHgLfy4zeB66IiMOBY4Ev\npr8jq/L5bLSbfQzw7xGxMiLeB+4C/rLOMTWrnoPynhCYUUT8Aljfo7jU/ftL4EcR8X5ErAT+neRz\nbJS8l7Dj5xN8L/sVEa9FxLL0dTfwHLA3Vfp8NlpC2Bv4Q9Hxy2mZlSeARyQ9KenitMwTAndOqfu3\nF8nntMCf2Wwuk/SUpHlF3Ru+l2WQtD8wBfgNVfp8NlpC8Ah3dUyNiCnAdJIm5fHFP/SEwJ2T4f75\n3vbtZmASyRpnq4E5fbzX97IXkkYDPwYuj4iNxT/bmc9noyWEV4B9i473ZfvsZhlExOr0++vAvSRN\nxDWS9gRIJwSurV+ETanU/ev5md0nLbMSImJtpIBb2NaF4XuZgaRhJMngjogozOOqyuez0RLCk8DB\nkvaXNJxkMOT+OsfUVCSNlLRr+noUcCqwnG0TAqGPCYFWUqn7dz9wnqThkiYBBwNL6hBf00h/YRWc\nTfL5BN/LfkkSMA94NiJuKvpRVT6fuc1UrkREbJF0KfAwyYS2eRHxXJ3DajbjgXuTzw1DgX+JiIWS\nngTmS+ognRBYvxAbm6QfAScAYyX9AfjvJLPsd7h/EfGspPnAs8AW4AvhyT0f6uVeXge0S5pM0nXx\nInAJ+F5mNBX4LPC0pKVp2deo0ufTE9PMzAxovC4jMzOrEycEMzMDnBDMzCzlhGBmZoATgpmZpZwQ\nzMwMcEKwQUBSd/p9oqTzq3zta3oc/7Ka1zerJScEGwwKk20mAZ8p50RJ/U3e/Np2FUVMLef6Zo3E\nCcEGk28Bx6ebslwuaRdJ/yhpSbry5iwASe2SfiHpJ8Azadl96eqxzxRWkJX0LWBEer070rJCa0Tp\ntZcr2azo3KJrd0m6R9Jzkn5Yh/tg1quGWrrCLGdXAV+JiDMB0gSwISKOkfQR4HFJC9P3TgEOj4iX\n0uOLImK9pBHAEkn/JyKulvTFdGXZgkJr5BzgSOAIYBzwhKSfpz+bTLJhyWrgl5KmRoS7mqzu3EKw\nwaTnpiynAhema8L8X6ANOCj92ZKiZABwuaRlwK9JVo88uJ+6pgF3pot6rgUWA0eTJIwlEfFquqbM\nMmD/nfg3mVWNWwg22F0aEYuKCyS1A2/3OP5z4NiIeFfSY0BLP9cNdkxAhdbDe0VlH+D/D61BuIVg\ng8lGYNei44eBLxQGjiUdImlkL+eNAdanyeBQkr1sC94vMfD8C+Cv03GKccCfkSw73NvWkWYNwX+Z\n2GBQ+Mv8KeCDtOvnVuB/kHTX/C5dZ34tyfr8PXecWgB8XtKzwAsk3UYFc0mWIv5tRPyXwnkRca+k\nP03rDODKiFibbojec4lhLzlsDcHLX5uZGeAuIzMzSzkhmJkZ4IRgZmYpJwQzMwOcEMzMLOWEYGZm\ngBOCmZmlnBDMzAyA/w+/yklsKjjwrAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10794a590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parameters of the algorithms\n",
    "rho = float(1)/50    # Learning step\n",
    "n_it = 200   # Number of iterations\n",
    "\n",
    "# Compute Z's\n",
    "Z_tr = np.c_[np.ones(n_tr), Xn_tr] \n",
    "Z_tst = np.c_[np.ones(n_tst), Xn_tst]\n",
    "n_dim = Z_tr.shape[1]\n",
    "\n",
    "# Convert target arrays to column vectors\n",
    "Y_tr2 = Y_tr[np.newaxis].T\n",
    "Y_tst2 = Y_tst[np.newaxis].T\n",
    "\n",
    "# Running the gradient descent algorithm\n",
    "w, nll_tr = logregFit(Z_tr, Y_tr2, rho, n_it)\n",
    "\n",
    "# Classify training and test data\n",
    "p_tr, D_tr = logregPredict(Z_tr, w)\n",
    "p_tst, D_tst = logregPredict(Z_tst, w)\n",
    "    \n",
    "# Compute error rates\n",
    "E_tr = D_tr!=Y_tr\n",
    "E_tst = D_tst!=Y_tst\n",
    "\n",
    "# Error rates\n",
    "pe_tr = float(sum(E_tr)) / n_tr\n",
    "pe_tst = float(sum(E_tst)) / n_tst\n",
    "\n",
    "# NLL plot.\n",
    "plt.plot(range(n_it), nll_tr,'b.:', label='Train')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Negative Log-Likelihood')\n",
    "plt.legend()\n",
    "\n",
    "print \"The optimal weights are:\"\n",
    "print w\n",
    "print \"The final error rates are:\"\n",
    "print \"- Training: \" + str(pe_tr)\n",
    "print \"- Test: \" + str(pe_tst)\n",
    "print \"The NLL after training is \" + str(nll_tr[len(nll_tr)-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3. Free parameters\n",
    "\n",
    "Under certaing conditions, the gradient descent method can be shown to converge assymtotically (i.e. as the number of iterations goes to infinity) to the ML estimate of the logistic model. However, in practice, the final estimate of the weights ${\\bf w}$ depend on several factors:\n",
    "\n",
    "- Number of iterations\n",
    "- Initialization\n",
    "- Learning step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Visualize the variability of gradient descent caused by initializations. To do so, fix the number of iterations to 200 and the learning step, and execute the gradient descent 100 times, storing the training error rate of each execution. Plot the histogram of the error rate values.\n",
    "\n",
    "Note that you can do this exercise with a loop over the 100 executions, including the code in the previous code slide inside the loop, with some proper modifications. To plot a histogram of the values in array `p` with `n`bins, you can use `plt.hist(p, n)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.3.1. Learning step\n",
    "\n",
    "The learning step, $\\rho$, is a free parameter of the algorithm. Its choice is critical for the convergence of the algorithm. too large values of $\\rho$ make the algorithm diverge. For too small values, the convergence is too slown and more iterations are required for a good convergence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3**: Observe the evolution of the negative log-likelihood with the number of iterations, for different values of $\\rho$. It is easy to check that, for $\\rho$ large enough, the gradient descent method does not converge. Can you estimate (through manual observation) and approximate value of $\\rho$ stating a boundary between convergence and non-convergence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4**: In this exercise we explore the influence of the learning step more sistematically. Use the code in the previouse exercises to compute, for every value of $\\rho$, the average error rate over 100 executions. Plot the average error rate vs. $\\rho$. \n",
    "\n",
    "Note that you should explore the values of $\\rho$ in a logarithmic scale. For instance, you can take $\\rho = 1, 1/10, 1/100, 1/1000, \\ldots$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, the selection of $\\rho$ may be a matter of trial an error. Also there is some theoretical evidence that the learning step should decrease along time up to cero, and the sequence $\\rho_n$ should satisfy two conditions:\n",
    "- C1: $\\sum_{n=0}^{\\infty} \\rho_n^2 < \\infty$ (decrease slowly)\n",
    "- C2: $\\sum_{n=0}^{\\infty} \\rho_n = \\infty$ (do not decrease too much slowly)\n",
    "\n",
    "For instance, we can take $\\rho_n= 1/n$. Another common choice is $\\rho_n = \\alpha/(1+\\beta n)$ where $\\alpha$ and $\\beta$ are also free parameters that can be selected by trial and error with some heuristic method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4. Visualizing the posterior map.\n",
    "\n",
    "We can also visualize the posterior probability map estimated by the logistic regression model for the estimated weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.contour.QuadContourSet instance at 0x107aa85f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEMCAYAAADDMN02AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZHL/H9rwdRfVnh5VgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10280be90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a regtangular grid.\n",
    "x_min, x_max = Xn_tr[:, 0].min(), Xn_tr[:, 0].max() \n",
    "y_min, y_max = Xn_tr[:, 1].min(), Xn_tr[:, 1].max()\n",
    "dx = x_max - x_min\n",
    "dy = y_max - y_min\n",
    "h = dy /400\n",
    "xx, yy = np.meshgrid(np.arange(x_min - 0.1 * dx, x_max + 0.1 * dx, h),\n",
    "                     np.arange(y_min - 0.1 * dx, y_max + 0.1 * dy, h))\n",
    "X_grid = np.array([xx.ravel(), yy.ravel()]).T\n",
    "\n",
    "# Compute Z's\n",
    "Z_grid = np.c_[np.ones(X_grid.shape[0]), X_grid] \n",
    "\n",
    "# Compute the classifier output for all samples in the grid.\n",
    "pp, dd = logregPredict(Z_grid, w)\n",
    "\n",
    "# Put the result into a color plot\n",
    "plt.plot(x0c0, x1c0,'r.', label=labels[c0])\n",
    "plt.plot(x0c1, x1c1,'g+', label=labels[c1])\n",
    "plt.xlabel('$x_' + str(ind[0]) + '$')\n",
    "plt.ylabel('$x_' + str(ind[1]) + '$')\n",
    "plt.legend(loc='best')\n",
    "plt.axis('equal')\n",
    "pp = pp.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, pp, cmap=plt.cm.copper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.5. Polynomial Logistic Regression\n",
    "\n",
    "The error rates of the logitic regression model can be potentially reduce by using polynomial transformations.\n",
    "\n",
    "To compute the polinomial transformation up to a given degree, we can use the `PolynomialFeatures` method in `sklearn.preprocessing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal weights are:\n",
      "[[ 0.60540481]\n",
      " [ 1.26644588]\n",
      " [ 0.0916665 ]\n",
      " [-2.20412289]\n",
      " [ 0.97864553]\n",
      " [-0.83616536]\n",
      " [ 0.28858738]\n",
      " [-0.07280199]\n",
      " [ 1.09552117]\n",
      " [ 1.86237099]\n",
      " [ 3.88830239]\n",
      " [ 1.01656416]\n",
      " [-3.90169614]\n",
      " [ 2.03193089]\n",
      " [ 1.8108233 ]\n",
      " [-0.78435048]\n",
      " [ 0.02628487]\n",
      " [ 0.83488124]\n",
      " [ 0.43468305]\n",
      " [-0.10673226]\n",
      " [-1.2449976 ]]\n",
      "The final error rates are:\n",
      "- Training: 0.169230769231\n",
      "- Test: 0.428571428571\n",
      "The NLL after training is 28.1133853647\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEPCAYAAABCyrPIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOCGYmVnKCcHMzAAnBDMzSzkhmJkZAP8fqXA8USvyJ+QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10809c4d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parameters of the algorithms\n",
    "rho = float(1)/50    # Learning step\n",
    "n_it = 500   # Number of iterations\n",
    "g = 5 # Degree of polynomial\n",
    "\n",
    "# Compute Z_tr\n",
    "poly = PolynomialFeatures(degree=g)\n",
    "Z_tr = poly.fit_transform(Xn_tr)\n",
    "# Normalize columns (this is useful to make algorithms more stable).)\n",
    "Zn, mz, sz = normalize(Z_tr[:,1:])\n",
    "Z_tr = np.concatenate((np.ones((n_tr,1)), Zn), axis=1)\n",
    "\n",
    "# Compute Z_tst\n",
    "Z_tst = poly.fit_transform(Xn_tst)\n",
    "Zn, mz, sz = normalize(Z_tst[:,1:], mz, sz)\n",
    "Z_tst = np.concatenate((np.ones((n_tst,1)), Zn), axis=1)\n",
    "\n",
    "# Convert target arrays to column vectors\n",
    "Y_tr2 = Y_tr[np.newaxis].T\n",
    "Y_tst2 = Y_tst[np.newaxis].T\n",
    "\n",
    "# Running the gradient descent algorithm\n",
    "w, nll_tr = logregFit(Z_tr, Y_tr2, rho, n_it)\n",
    "\n",
    "# Classify training and test data\n",
    "p_tr, D_tr = logregPredict(Z_tr, w)\n",
    "p_tst, D_tst = logregPredict(Z_tst, w)\n",
    "    \n",
    "# Compute error rates\n",
    "E_tr = D_tr!=Y_tr\n",
    "E_tst = D_tst!=Y_tst\n",
    "\n",
    "# Error rates\n",
    "pe_tr = float(sum(E_tr)) / n_tr\n",
    "pe_tst = float(sum(E_tst)) / n_tst\n",
    "\n",
    "# NLL plot.\n",
    "plt.plot(range(n_it), nll_tr,'b.:', label='Train')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Negative Log-Likelihood')\n",
    "plt.legend()\n",
    "\n",
    "print \"The optimal weights are:\"\n",
    "print w\n",
    "print \"The final error rates are:\"\n",
    "print \"- Training: \" + str(pe_tr)\n",
    "print \"- Test: \" + str(pe_tst)\n",
    "print \"The NLL after training is \" + str(nll_tr[len(nll_tr)-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the posterior map we can se that the polynomial transformations produces nonlinear decision boundaries."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
