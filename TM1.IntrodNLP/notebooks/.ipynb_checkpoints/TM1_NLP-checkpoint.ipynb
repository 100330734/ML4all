{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Text Analysis with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Author: Jesús Cid-Sueiro\n",
    "\n",
    "Date: 2016/04/03\n",
    "\n",
    "Last review: 2016/11/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jcid/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Required imports\n",
    "from wikitools import wiki\n",
    "from wikitools import category\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from time import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "\n",
    "from test_helper import Test\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Corpus acquisition.\n",
    "In this notebook we will explore some tools for text analysis available from Python toolboxes.\n",
    "\n",
    "To do so, we will explore and analyze collections of Wikipedia articles from a given category, using `wikitools`, that makes the capture of content from wikimedia sites very easy.\n",
    "\n",
    "(*As a side note, there are many other available text collections to work with. In particular, the NLTK library has many examples, that you can explore using the `nltk.download()` tool*.\n",
    "\n",
    "    import nltk\n",
    "    nltk.download()\n",
    "\n",
    "*for instance, you can take the gutemberg dataset*\n",
    "\n",
    "    Mycorpus = nltk.corpus.gutenberg\n",
    "    text_name = Mycorpus.fileids()[0]\n",
    "    raw = Mycorpus.raw(text_name)\n",
    "    Words = Mycorpus.words(text_name)\n",
    "\n",
    "*Also, tools like Gensim or Sci-kit learn include text databases to work with*).\n",
    "\n",
    "In order to use Wikipedia data, we will select a single category of articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudoscience\n"
     ]
    }
   ],
   "source": [
    "site = wiki.Wiki(\"https://en.wikipedia.org/w/api.php\")\n",
    "# Select a category with a reasonable number of articles (>100)\n",
    "# cat = \"Economics\"\n",
    "cat = \"Pseudoscience\"\n",
    "print cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try with any other categories, but take into account that some categories may contain very few articles. Select a category with at least 100 articles. You can browse the wikipedia category tree here, https://en.wikipedia.org/wiki/Category:Contents, for instance, and select the appropriate one.\n",
    "\n",
    "We start downloading the text collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category data. This may take a while...\n",
      " Loading article 365 \n",
      "Loaded 365 articles from category Pseudoscience\n"
     ]
    }
   ],
   "source": [
    "# Loading category data. This may take a while\n",
    "print \"Loading category data. This may take a while...\"\n",
    "cat_data = category.Category(site, cat)\n",
    "\n",
    "corpus_titles = []\n",
    "corpus_text = []\n",
    "\n",
    "for n, page in enumerate(cat_data.getAllMembersGen()):\n",
    "    print \"\\r Loading article {0}\".format(n + 1),\n",
    "    corpus_titles.append(page.title)\n",
    "    corpus_text.append(page.getWikiText())\n",
    "\n",
    "n_art = len(corpus_titles)\n",
    "print \"\\nLoaded \" + str(n_art) + \" articles from category \" + cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have stored the whole text collection in two lists:\n",
    "\n",
    "* `corpus_titles`, which contains the titles of the selected articles\n",
    "* `corpus_text`, with the text content of the selected wikipedia articles\n",
    "\n",
    "You can browse the content of the wikipedia articles to get some intuition about the kind of documents that will be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All About Radiation\n",
      "{{Use dmy dates|date=April 2012}}\n",
      "[[File:WPA quack poster.jpg|thumb|right|1930s public information poster warning of \"cancer quacks\"<ref>{{cite web\n",
      "|url=http://www.loc.gov/pictures/item/98518641/\n",
      "|publisher=[[Library of Congress]]\n",
      "|title=Beware the cancer quack A reputable physician does not promise a cure, demand advance payment, advertise\n",
      "|accessdate=15 August 2013}}</ref>]]\n",
      "'''Alternative cancer treatments''' are [[Alternative medicine|alternative or complementary treatments]] for [[cancer]] that have not been approved by the government agencies responsible for the [[regulation of therapeutic goods]].  They include diet and exercise, chemicals, herbs, devices, and manual procedures. The treatments are not supported by [[evidence-based medicine|evidence]], either because no proper testing has been conducted, or because testing did not demonstrate [[statistically significant]] efficacy.  Concerns have been raised about the safety of some of them. Some treatments that have been proposed in the past have been found in clinical trials to be useless or unsafe.  Some of these obsolete or disproven treatments continue to be promoted, sold, and used. Promoting or marketing such treatments is illegal in most of the developed world including the United States and European Union.\n",
      "\n",
      "A distinction is typically made between complementary treatments which do not disrupt conventional medical treatment, and alternative treatments which may replace conventional treatment.  \n",
      "Alternative cancer treatments are typically contrasted with [[experimental cancer treatment]]s&nbsp;&ndash; which are treatments for which experimental testing is underway&nbsp;&ndash; and with complementary treatments, which are non-invasive practices used alongside other treatment. All approved [[chemotherapeutic]] cancer treatments were considered experimental cancer treatments before their safety and efficacy testing was completed.\n",
      "\n",
      "Since the 1940s, medical science has [[history of cancer chemotherapy|developed chemotherapy]], [[radiation therapy]], [[adjuvant therapy]] and the newer [[targeted therapies]], as well as refined [[oncosurgery|surgical techniques]] for removing cancer.  Before the development of these modern, evidence-based treatments, 90% of cancer patients died within five years.<ref>{{cite journal |url=http://www.slate.com/id/2268104/ |title=Who's a Survivor? |author = Schattner,  Elaine |journal=Slate Magazine |date=5 October 2010}}</ref>  With modern mainstream treatments, only 34% of cancer patients die within five years.<ref>{{cite web |url=http://seer.cancer.gov/statfacts/html/all.html#survival |title=Cancer of All Sites - SEER Stat Fact Sheets |accessdate=6 October 2010| archiveurl= https://web.archive.org/web/20100926191037/http://seer.cancer.gov/statfacts/html/all.html| archivedate= 26 September 2010 <!--DASHBot-->| deadurl= no}}</ref>  However, while mainstream forms of cancer treatment generally prolong life or permanently cure cancer, most treatments also have side effects ranging from unpleasant to fatal, such as pain, blood clots, fatigue, and infection.<ref name=Complications>{{cite web|last=McMillen|first=Matt|title=8 Common Surgery Complications|url=http://www.webmd.com/healthy-aging/features/common-surgery-complications|work=WebMD Feature|publisher=WebMD|accessdate=2013-03-31}}</ref> These side effects and the lack of a guarantee that treatment will be successful create appeal for alternative treatments for cancer, which purport to cause fewer side effects or to increase survival rates.\n",
      "\n",
      "Alternative cancer treatments have typically not undergone properly conducted, well-designed clinical trials, or the results have not been published due to [[publication bias]] (a refusal to publish results of a treatment outside that journal's focus area, guidelines or approach).  Among those that have been published, the methodology is often poor.  A 2006 systematic review of 214 articles covering 198 clinical trials of alternative cancer treatments concluded that almost none conducted [[dose-ranging]] studies, which are necessary to ensure that the patients are being given a useful amount of the treatment.<ref name=Vickers2006>{{cite journal |vauthors=Vickers AJ, Kuo J, Cassileth BR |title=Unconventional anticancer agents: a systematic review of clinical trials |journal=Journal of Clinical Oncology |volume=24 |issue=1 |pages=136–40 |date=January 2006 |pmid=16382123 |pmc=1472241 |doi=10.1200/JCO.2005.03.8406}}</ref>  These kinds of treatments appear and vanish frequently, and have throughout history.<ref name=Cassileth1996/>\n",
      "\n",
      "==Terminology==\n",
      "Complementary and alternative cancer treatments are often grouped together, in part because of the adoption of the phrase \"complementary and alternative medicine\" by the United States Congress.<ref name=\"whccamp.hhs.gov\">{{cite book |title=White House Commission on Complementary and Alternative Medicine Policy |url=http://whccamp.hhs.gov/fr2.html |chapter=Overview of CAM in the United States: Recent History, Current Status, And Prospects for the Future |date=March 2002}}</ref> However, according to [[Barrie R. Cassileth]], in cancer treatment the distinction between complementary and alternative therapies is \"crucial\".<ref name=Cassileth1996/>\n",
      "\n",
      "Complementary treatments are used in conjunction with proven mainstream treatments. They tend to be pleasant for the patient, not involve substances with any pharmacological effects, inexpensive, and intended to treat side effects rather than to kill cancer cells.<ref>{{cite journal |vauthors=Wesa KM, Cassileth BR |title=Is there a role for complementary therapy in the management of leukemia? |journal=Expert Rev Anticancer Ther |volume=9 |issue=9 |pages=1241–9 |date=September 2009 |pmid=19761428 |pmc=2792198 |doi=10.1586/era.09.100 }}</ref>  [[Medical massage]] and [[self-hypnosis]] to treat pain are examples of complementary treatments.\n",
      "\n",
      "About half the practitioners who dispense complementary treatments are physicians, although they tend to be generalists rather than [[oncologist]]s. As many as 60% of American physicians have referred their patients to a complementary practitioner for some purpose.<ref name=Cassileth1996>{{cite journal |author =Cassileth BR |title=Alternative and Complementary Cancer Treatments |journal=The Oncologist |volume=1 |issue=3 |pages=173–179 |year=1996 |pmid=10387984 |url=http://theoncologist.alphamedpress.org/cgi/pmidlookup?view=long&pmid=10387984}}</ref>\n",
      "\n",
      "Alternative treatments, by contrast, are used in place of mainstream treatments. The most popular alternative cancer therapies include restrictive [[diets]], [[mind-body intervention]]s, [[bioelectromagnetic]]s, [[nutritional supplement]]s, and [[herbology|herbs]].<ref name=Cassileth1996/> The popularity and prevalence of different treatments varies widely by region.<ref name=Cassileth2001>{{cite journal |vauthors=Cassileth BR, Schraub S, Robinson E, Vickers A |title=Alternative medicine use worldwide: the International Union Against Cancer survey |journal=Cancer |volume=91 |issue=7 |pages=1390–3 |date=April 2001 |pmid=11283941 |doi=10.1002/1097-0142(20010401)91:7<1390::AID-CNCR1143>3.0.CO;2-C}}</ref>  While conventional physicians should always be kept aware of any complementary treatments used by a patient, many physicians in the United Kingdom are at least tolerant of their use, and some might recommend them.<ref>[http://www.cancerresearchuk.org/about-cancer/cancers-in-general/treatment/complementary-alternative/about/the-difference-between-complementary-and-alternative-therapies \"The difference between complementary and alternative therapies\"], [[Cancer Research UK]], accessed 20 November 2014</ref>\n",
      "\n",
      "==Extent of their use==\n",
      "Survey data about how many cancer patients use alternative or complementary therapies vary from nation to nation as well from region to region. A 2000 study published by the ''[[European Journal of Cancer]]'' evaluated a sample of 1023 women from a British cancer registry suffering from [[breast cancer]] and found that 22.4% had consulted with a practitioner of complementary therapies in the previous twelve months. The study concluded that the patients had spent many thousands of pounds on such measures and that use \"of practitioners of complementary therapies following diagnosis is a significant and possibly growing phenomenon\".<ref>http://www.ejcancer.com/article/S0959-8049(00)00099-X/abstract?cc=y?cc=y</ref>\n",
      "\n",
      "In [[Australia]], one study reported that 46% of children suffering from cancer have been treated with at least one non-traditional therapy. Further 40% of those of any age receiving [[palliative care]] had tried at least one such therapy. Some of the most popular alternative cancer treatments were found to be dietary therapies, antioxidants, high dose vitamins, and herbal therapies.<ref>https://www.mja.com.au/journal/2000/172/3/australian-oncologists-self-reported-knowledge-and-attitudes-about-non</ref>\n",
      "\n",
      "Use of unconventional cancer treatments in the United States has been influenced by the U.S. federal government's [[National Center for Complementary and Alternative Medicine]] (NCCAM), initially known as the Office of Alternative Medicine (OAM), which was established in 1992 as a [[National Institutes of Health]] (NIH) adjunct by the [[U.S. Congress]]. Over thirty American [[medical schools]] have offered general courses in alternative medicine, including the [[Georgetown University|Georgetown]], [[Columbia University|Columbia]], and [[Harvard University|Harvard]] university systems, among others.<ref name=Cassileth1996/>\n",
      "\n",
      "==People who choose alternative treatments==\n",
      "People who choose alternative treatments tend to believe that evidence-based medicine is extremely invasive or ineffective, while still believing that their own health could be improved.<ref name=\"pmid8071452\">{{cite journal |vauthors=Furnham A, Forey J |title=The attitudes, behaviors and beliefs of patients of conventional vs. complementary (alternative) medicine |journal=J Clin Psychol |volume=50 |issue=3 |pages=458–69 |date=May 1994 |pmid=8071452 |doi=10.1002/1097-4679(199405)50:3<458::AID-JCLP2270500318>3.0.CO;2-V }}</ref>  They are [[loyalty|loyal]] to their alternative healthcare providers and believe that \"treatment should concentrate on the whole person\".<ref name=\"pmid8071452\"/>\n",
      "\n",
      "Cancer patients who choose alternative treatments instead of conventional treatments believe themselves less likely to die than patients who choose only conventional treatments.<ref name=\"pmid16504038\">{{cite journal |vauthors=Helyer LK, Chin S, Chui BK |title=The use of complementary and alternative medicines among patients with locally advanced breast cancer--a descriptive study |journal=BMC Cancer |volume=6|pages=39 |year=2006 |pmid=16504038 |pmc=1475605 |doi=10.1186/1471-2407-6-39 |url=|display-authors=etal}}</ref>  They feel a greater sense of control over their destinies, and report less anxiety and depression.<ref name=\"pmid16504038\"/>  They are more likely to engage in [[benefit finding]], which is the psychological process of adapting to a traumatic situation and deciding that the trauma was valuable, usually because of perceived personal and spiritual growth during the crisis.<ref>{{cite journal |vauthors=Garland SN, Valentine D, Desai K |title=Complementary and alternative medicine use and benefit finding among cancer patients |journal=J Altern Complement Med |volume=19 |issue=11 |pages=876–81 |date=November 2013  |pmid=23777242 |doi=10.1089/acm.2012.0964|display-authors=etal}}</ref>\n",
      "\n",
      "However, patients who use alternative treatments have a poorer survival time, even after controlling for type and stage of disease.<ref name=Vickers /> The reason that patients using alternative treatments die sooner may be because patients who accurately perceive that they are likely to survive do not attempt unproven remedies, and patients who accurately perceive that they are unlikely to survive are attracted to unproven remedies.<ref name=Vickers />  Among patients who believe their condition to be untreatable by evidence-based medicine, \"desperation drives them into the hands of anyone with a promise and a smile.\"<ref name=\"Olson\">{{cite book |author =Olson, James Stuart |title=Bathsheba's breast: women, cancer & history |publisher=The Johns Hopkins University Press |location=Baltimore |year=2002 |pages=146 |isbn=0-8018-6936-6 }}</ref>  [[Con artist]]s have long exploited patients' perceived lack of options to extract payments for ineffectual and even harmful treatments.<ref name=\"Olson\" />\n",
      "\n",
      "In a survey of American cancer patients, [[Baby boomers|Baby Boomers]] were more likely to support complementary and alternative treatments than people from an older generation.<ref name=\":1\">{{Cite journal|title = Do attitudes and beliefs regarding complementary and alternative medicine impact its use among patients with cancer? A cross-sectional survey|url = http://doi.wiley.com/10.1002/cncr.29173|journal = Cancer|author = Bauml, J. M.|author2 = Chokshi, S.|author3 = Schapira, M. M.|author4 = Im, E.-O.|author5 = Li, S. Q.|author6 = Langer, C. J.|author7 = Ibrahim, S. A.|author8 = Mao, J. J.|last-author-amp = yes|doi = 10.1002/cncr.29173|date = 26 May 2015|lay-url = http://www.reuters.com/article/2015/05/26/us-cancer-treatment-alternative-idUSKBN0OB2G120150526|lay-source = Reuters|lay-date = 26 May 2015|volume=121|pages=2431–2438}}</ref>  White, female, college-educated patients who had been diagnosed more than a year ago were more likely than others to report a favorable impression of at least some complementary and alternative benefits.<ref name=\":1\" />\n",
      "\n",
      "==Questionable and ineffective treatments==\n",
      ":{{main article|List of unproven and disproven cancer treatments}}\n",
      "Many [[therapy|therapies]] have been (and continue to be) promoted to treat or prevent cancer in humans but lack good scientific and medical evidence of effectiveness.  In many cases, there is good scientific evidence that the alleged treatments do not work. Unlike [[management of cancer|accepted cancer treatments]], unproven and disproven treatments are generally ignored or avoided by the [[medicine|medical community]], and are often [[pseudoscientific]].<ref name=pseudoscientific>{{cite journal |author =Green S |title=Pseudoscience in Alternative Medicine: Chelation Therapy, Antineoplastons, The Gerson Diet and Coffee Enemas |journal=Skeptical Inquirer |volume=21 |issue=5 |year=1997 |page=39}}</ref>\n",
      "\n",
      "Despite this, many of these therapies have continued to be promoted as effective, particularly by promoters of [[alternative medicine]]. Scientists consider this practice [[quackery]],<ref>{{cite journal |vauthors=Cassileth BR, Yarett IR |title=Cancer quackery: the persistent popularity of useless, irrational 'alternative' treatments |journal=Oncology (Williston Park, N.Y.) |volume=26 |issue=8 |pages=754–8 |date=August 2012  |pmid=22957409}}</ref><ref>{{cite journal |author =Lerner IJ |title=The whys of cancer quackery |journal=Cancer |volume=53 |issue=3 Suppl |pages=815–9 |date=February 1984  |pmid=6362828 |doi=10.1002/1097-0142(19840201)53:3+<815::aid-cncr2820531334>3.0.co;2-u}}</ref> and some of those engaged in it have been investigated and prosecuted by [[public health]] [[regulatory agency|regulators]] such as the US [[Federal Trade Commission]],<ref name=nw>{{cite journal\n",
      "|title=Court orders Seasilver defendants to pay $120 million\n",
      "|journal=Nutraceuticals World\n",
      "|volume=11\n",
      "|issue=6\n",
      "|year=2008\n",
      "|page=14}}</ref> the Mexican [[Secretariat of Health]]<ref name=qw-zoetron>{{cite web\n",
      "|title=Zoetron Therapy (Cell Specific Cancer Therapy)\n",
      "|url=http://www.quackwatch.org/01QuackeryRelatedTopics/Cancer/csct.html\n",
      "|author =Stephen Barrett, M.D.\n",
      "|publisher=[[Quackwatch]]\n",
      "|accessdate=15 September 2013\n",
      "|date=1 March 2004}}</ref> and the Canadian [[Competition Bureau]].<ref name=bbb>{{cite web|url=http://www.bbb.org/mbc/business-reviews/occupational-health-and-safety/zoetron-cell-specific-cancer-therapy-in-penticton-bc-1143287|title=Zoetron Cell Specific Cancer Therapy|publisher=BBB Business Review|accessdate=14 September 2013}}</ref> In the [[United Kingdom]], the [[Cancer Act 1939|Cancer Act]] makes the unauthorized promotion of cancer treatments a criminal offense.<ref>{{cite news |url=http://www.telegraph.co.uk/news/uknews/law-and-order/10510345/Harley-Street-practitioner-claimed-he-could-cure-cancer-and-HIV-with-lifestyle-changes-and-herbs-court-hears.html |newspaper=[[Daily Telegraph]] |title=Harley Street practitioner claimed he could cure cancer and HIV with lifestyle changes and herbs, court hears |date=11 December 2013}}</ref><ref>{{citation |url=http://www.legislation.gov.uk/ukpga/Geo6/2-3/13/section/4 |title=Cancer Act 1939 section 4 |date=7 May 2014}}</ref>\n",
      "\n",
      "==Areas of research==\n",
      "{{Distinguish|Experimental cancer treatment}}\n",
      "\n",
      "===Specific methods===\n",
      "* [[Curcumin]]\n",
      "* [[Deoxycholic acid]]\n",
      "* [[Dichloroacetic acid]]\n",
      "* [[HuaChanSu]], traditional Chinese medicine extracted from the skin of the Bufo toad<ref>{{cite web|title=HuaChanSu|url=http://www.cancer.gov/drugdictionary?cdrid=637352|publisher=National Cancer Institute|accessdate=17 November 2012}}</ref><ref name=\"ncbi\">{{cite journal|last=Meng|first=Zhigiang|title=Pilot Study of Huachansu in Patients with Hepatocellular Carcinoma, Non-Small Cell Lung Cancer, or Pancreatic Cancer|publisher=NIHPA|pmc=2856335|year=2009|last2=Yang|first2=P|last3=Shen|first3=Y|last4=Bei|first4=W|last5=Zhang|first5=Y|last6=Ge|first6=Y|last7=Newman|first7=RA|last8=Cohen|first8=L|last9=Liu|first9=L|\n",
      "displayauthors=8|volume=115|issue=22|pages=5309–5318|doi=10.1002/cncr.24602|journal=Cancer|pmid=19701908}}</ref>\n",
      "* [[Medical cannabis]] (especially for \"Appetite Stimulation\" and \"Analgesia\")<ref name=cannabis>{{cite web |url=http://www.cancer.gov/cancertopics/pdq/cam/cannabis/healthprofessional/page4#Section_32 |title=Cannabis and Cannabinoids:Appetite Stimulation|accessdate=1 October 2013}}</ref>\n",
      "* [[Melittin|Melittin (via \"Nanobees\")]]\n",
      "* [[Milk thistle]]\n",
      "* [[Proton therapy]]\n",
      "* [[Selenium]] (Selenomethionine and [[Se-methylselenocysteine|''Se''-methylselenocysteine]])<ref>{{cite journal |vauthors=Vadgama JV, Wu Y, Shen D, Hsia S, Block J |title=Effect of selenium in combination with Adriamycin or Taxol on several different cancer cells |journal=Anticancer Research |volume=20 |issue=3A |pages=1391–414 |year=2000 |pmid=10928049}}</ref><ref>{{cite journal |vauthors=Nilsonne G, Sun X, Nyström C |title=Selenite induces apoptosis in sarcomatoid malignant mesothelioma cells through oxidative stress |journal=Free Radical Biology & Medicine |volume=41 |issue=6 |pages=874–85 |date=September 2006 |pmid=16934670 |doi=10.1016/j.freeradbiomed.2006.04.031|display-authors=etal}}</ref>\n",
      "\n",
      "===Pain relief===\n",
      "Most studies of complementary and alternative medicine in the treatment of [[cancer pain]] are of low quality in terms of scientific evidence. Studies of [[massage therapy]] have produced mixed results, but overall show some temporary benefit for reducing pain, anxiety, and depression and a very low risk of harm, unless the patient is at risk for bleeding disorders.<ref>{{Cite journal|title = The use of massage therapy for reducing pain, anxiety, and depression in oncological palliative care patients: a narrative review of the literature|journal = ISRN nursing|date = 2011|issn = 2090-5491|pmc = 3168862|pmid = 22007330|pages = 929868|volume = 2011|doi = 10.5402/2011/929868|first = Maria|last = Falkensteiner|first2 = Franco|last2 = Mantovan|first3 = Irene|last3 = Müller|first4 = Christa|last4 = Them}}</ref><ref>{{Cite web|url = http://www.cam-cancer.org/CAM-Summaries/Manipulative-body-based/Massage-Classical-Swedish|title = Massage (Classical/Swedish)|date = 17 December 2013|accessdate = |website = |publisher = CAM-Cancer Consortium|last = Cooke|first = Helen|last2 = Seers|first2 = Helen}}</ref>  There is weak evidence for a modest benefit from hypnosis, [[supportive psychotherapy]] and [[cognitive therapy]].  Results about Reiki and touch therapy were inconclusive.  The most studied such treatment, acupuncture, has demonstrated no benefit as an adjunct analgesic in cancer pain. The evidence for [[music therapy]] is equivocal, and some herbal interventions such as PC-SPES, mistletoe, and saw palmetto are known to be toxic to some cancer patients. The most promising evidence, though still weak, is for [[mind–body interventions]] such as [[biofeedback]] and [[Relaxation technique|relaxation]] techniques.<ref name = Induru>{{vcite journal |author =Induru RR, Lagman RL |title=Managing cancer pain: frequently asked questions |journal=Cleve Clin J Med |volume=78 |issue=7 |pages=449–64 |year=2011 |month=July |pmid=21724928 |doi=10.3949/ccjm.78a.10054 |url=http://www.ccjm.org/content/78/7/449.long }}</ref>\n",
      "\n",
      "==Examples of complementary therapy==\n",
      "As stated in the scientific literature, the measures listed below are defined as 'complementary' because they are applied in conjunction with mainstream anti-cancer measures such as chemotherapy, in contrast to the ineffective therapies viewed as 'alternative' since they are offered as substitutes for mainstream measures.<ref name=Cassileth1996/>\n",
      "\n",
      "* [[Acupuncture]] may help with nausea but does not treat the disease.<ref name =Ernst2007>{{cite journal |vauthors=Ernst E, Pittler MH, Wider B, Boddy K |title=Acupuncture: its evidence-base is changing |journal=The American Journal of Chinese Medicine |volume=35 |issue=1 |pages=21–5 |year=2007 |pmid=17265547 |doi=10.1142/S0192415X07004588}}</ref>\n",
      "* [[Psychotherapy]] may reduce [[anxiety]] and improve [[quality of life]] as well as allow for improving patient moods.<ref name=Vickers />\n",
      "* [[Massage therapy]] may temporarily reduce pain.<ref name = Induru/>\n",
      "* In laboratory animals, some [[cannabinoid]]s may stimulate appetite and reduce symptoms such as pain and nausea related to therapy, which helps reduce weight loss.<ref name=cannabis/> There is no evidence of similar effect for people.<ref name=cruk-cannabis>{{cite web|url=http://scienceblog.cancerresearchuk.org/2012/07/25/cannabis-cannabinoids-and-cancer-the-evidence-so-far/|title=Cannabis, cannabinoids and cancer – the evidence so far|last=Arney|first=Kat|date=2012-07-25|publisher=Cancer Research UK|accessdate=2014-12-03}}</ref>\n",
      "* [[Hypnosis]] and [[meditation]] may improve the quality of life of cancer patients.<ref>{{cite journal |vauthors=Vickers A, Zollman C, Payne DK |title=Hypnosis and relaxation therapies |journal=West. J. Med. |volume=175 |issue=4 |pages=269–72 |date=October 2001 |pmid=11577062 |pmc=1071579 |doi= 10.1136/ewjm.175.4.269|quote=Evidence from randomized controlled trials indicates that hypnosis, relaxation, and meditation techniques can reduce anxiety, particularly that related to stressful situations, such as receiving chemotherapy.}}</ref>\n",
      "* [[Music therapy]] eases cancer-related symptoms by helping with mood disturbances.<ref name=Vickers />\n",
      "\n",
      "==Alternative theories of cancer==\n",
      "Some alternative cancer treatments are based on unproven or disproven theories of how cancer begins or is sustained in the body.  Some common concepts are:\n",
      "\n",
      "* Mind-body connection:  This idea says that cancer forms because of, or can be controlled through, the person's mental and emotional state.  Treatments based on this idea are [[mind–body intervention]]s.  Proponents say that cancer forms because the person is unhappy or stressed, or that a positive attitude can cure cancer after it has formed.  A typical claim is that stress, anger, fear, or sadness depresses the immune system, whereas that love, forgiveness, confidence, and happiness cause the immune system to improve, and that this improved immune system will destroy the cancer.  This belief that generally boosting the immune system's activity will kill the cancer cells is not supported by any scientific research.<ref name=Thyphronitis>{{cite journal\n",
      "|vauthors=Thyphronitis G, Koutsilieris M |title=Boosting the immune response: an alternative combination therapy for cancer patients\n",
      "|journal=Anticancer Res.\n",
      "|volume=24\n",
      "|issue=4\n",
      "|pages=2443–53\n",
      "|year=2004\n",
      "|pmid=15330197\n",
      "|doi=\n",
      "|url=\n",
      "}}</ref>  In fact, many cancers require the support of an active immune system (especially through inflammation) to establish the [[tumor microenvironment]] necessary for a tumor to grow.<ref>{{cite news\n",
      "|title = A Malignant Flame\n",
      "|author = Stix, Gary\n",
      "|date = July 2007\n",
      "|journal = Scientific American Magazine\n",
      "|url = http://podcast.sciam.com/daily/pdf/sa_d_podcast_070619.pdf }}</ref>\n",
      "* Toxin theory of cancer:  In this idea, the body's metabolic processes are overwhelmed by normal, everyday byproducts.  These byproducts, called \"toxins\", are said to build up in the cells and cause cancer and other diseases through a process sometimes called ''[[wikt:autointoxication|autointoxication]]'' or ''autotoxemia''.  Treatments following this approach are usually aimed at detoxification or [[body cleansing]], such as enemas.\n",
      "* Low activity by the immune system:  This claim asserts that if only the body's [[immune system]] were strong enough, it would kill the \"invading\" or \"foreign\" cancer.  Unfortunately, most cancer cells retain normal cell characteristics, making them appear to the immune system to be a normal part of the body.  Cancerous tumors also actively induce [[immune tolerance]], which prevents the immune system from attacking them.<ref name=Thyphronitis />\n",
      "\n",
      "==Regulatory action==\n",
      "Government agencies around the world routinely investigate purported alternative cancer treatments in an effort to protect their citizens from fraud and abuse.\n",
      "\n",
      "In 2008, the [[United States Federal Trade Commission]] acted against companies that made unsupported claims that their products, some of which included highly toxic chemicals, could cure cancer.<ref>{{cite press release \n",
      "|url = http://www.ftc.gov/opa/2008/09/boguscures.shtm\n",
      "|title = FTC Sweep Stops Peddlers of Bogus Cancer Cures:  Public Education Campaign Counsels Consumers, \"Talk to Your Doctor\"\n",
      "|date = 18 September 2008\n",
      "|publisher = Federal Trade Commission\n",
      "}}</ref> Targets included Omega Supply, Native Essence Herb Company,  Daniel Chapter One, Gemtronics, Inc., Herbs for Cancer, Nu-Gen Nutrition, Inc., Westberry Enterprises, Inc., Jim Clark's All Natural Cancer Therapy, [[Soursop#Alternative cancer treatment|Bioque Technologies, Inc.]], Cleansing Time Pro, and Premium-essiac-tea-4less.\n",
      "\n",
      "==See also==\n",
      "{{portal|Medicine}}\n",
      "* [[Diet and cancer]]\n",
      "* [[Clinical trial]]\n",
      "* [[Placebo effect]]\n",
      "* [[Pseudoscience]]\n",
      "* [[List of topics characterized as pseudoscience]]\n",
      "\n",
      "==References==\n",
      "{{Research help|Med}}\n",
      "{{reflist|30em |refs=\n",
      "<ref name=Vickers>{{cite journal |last1=Vickers |first1=A. |title=Alternative Cancer Cures: 'Unproven' or 'Disproven'? |journal=CA |volume=54 |issue=2 |pages=110–8 |year=2004 |pmid=15061600 |doi=10.3322/canjclin.54.2.110 | url=http://onlinelibrary.wiley.com/doi/10.3322/canjclin.54.2.110/full }}</ref>\n",
      "}}\n",
      "\n",
      "==External links==\n",
      "* [http://www.ftc.gov/curious Cure-ious? Ask. If you or someone you care about has cancer, the last thing you need is a scam] from the US Federal Trade Commission\n",
      "* [http://www.fda.gov/Drugs/GuidanceComplianceRegulatoryInformation/EnforcementActivitiesbyFDA/ucm171057.htm 187 Cancer Cure Frauds] from the US Food and Drug Administration\n",
      "* [http://www.mskcc.org/mskcc/html/60783.cfm Herbs, Botanicals & Other Products] from Memorial Sloan-Kettering Cancer Center\n",
      "\n",
      "{{Pseudoscience}}\n",
      "{{Fraud}} \n",
      "{{American Cancer Society}} \n",
      "{{Francis Crick Institute}}\n",
      "\n",
      "[[Category:Pseudoscience]]\n",
      "[[Category:Alternative cancer treatments| ]]\n",
      "[[Category:Alternative medicine]]\n",
      "[[Category:Health fraud]]\n",
      "[[Category:Medical lists]]\n",
      "[[Category:Cancer in the United Kingdom]]\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "print corpus_titles[n]\n",
    "print corpus_text[n+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Corpus Processing\n",
    "\n",
    "Topic modelling algorithms process vectorized data. In order to apply them, we need to transform the raw text input data into a vector representation. To do so, we will remove irrelevant information from the text data and preserve as much relevant information as possible to capture the semantic content in the document collection.\n",
    "\n",
    "Thus, we will proceed with the following steps:\n",
    "\n",
    "1. Tokenization\n",
    "2. Homogeneization\n",
    "3. Cleaning\n",
    "4. Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Tokenization\n",
    "\n",
    "For the first steps, we will use some of the powerfull methods available from the [Natural Language Toolkit](http://www.nltk.org). In order to use the `word_tokenize` method from nltk, you might need to get the appropriate libraries using `nltk.download()`. You must select option \"d) Download\", and identifier \"punkt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can comment this if the package is already available.\n",
    "# Select option \"d) Download\", and identifier \"punkt\"\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Insert the appropriate call to `word_tokenize` in the code below, in order to get the tokens list corresponding to each Wikipedia article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_tokens = []\n",
    "\n",
    "for n, art in enumerate(corpus_text): \n",
    "    print \"\\rTokenizing article {0} out of {1}\".format(n + 1, n_art),\n",
    "    # This is to make sure that all characters have the appropriate encoding.\n",
    "    art = art.decode('utf-8')  \n",
    "    \n",
    "    # Tokenize each text entry. \n",
    "    # scode: tokens = <FILL IN>\n",
    "    tokens = word_tokenize(art)\n",
    "    \n",
    "    # Add the new token list as a new element to corpus_tokens (that will be a list of lists)\n",
    "    # scode: <FILL IN>\n",
    "    corpus_tokens.append(tokens)\n",
    "\n",
    "print \"\\n The corpus has been tokenized. Let's check some portion of the first article:\"\n",
    "print corpus_tokens[0][0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Test.assertEquals(len(corpus_tokens), n_art, \"The number of articles has changed unexpectedly\")\n",
    "Test.assertTrue(len(corpus_tokens) >= 100, \n",
    "                \"Your corpus_tokens has less than 100 articles. Consider using a larger dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Homogeneization\n",
    "\n",
    "By looking at the tokenized corpus you may verify that there are many tokens that correspond to punktuation signs and other symbols that are not relevant to analyze the semantic content. They can be removed using the stemming tool from `nltk`.\n",
    "\n",
    "The homogeneization process will consist of:\n",
    "\n",
    "1. Removing capitalization: capital alphabetic characters will be transformed to their corresponding lowercase characters.\n",
    "2. Removing non alphanumeric tokens (e.g. punktuation signs)\n",
    "3. Stemming/Lemmatization: removing word terminations to preserve the root of the words and ignore grammatical information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1. Filtering\n",
    "\n",
    "Let us proceed with the filtering steps 1 and 2 (removing capitalization and non-alphanumeric tokens)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Convert all tokens in `corpus_tokens` to lowercase (using `.lower()` method) and remove non alphanumeric tokens (that you can detect with `.isalnum()` method). You can do it in a single line of code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_filtered = []\n",
    "\n",
    "for n, token_list in enumerate(corpus_tokens):\n",
    "    print \"\\rFiltering article {0} out of {1}\".format(n + 1, n_art),\n",
    "    \n",
    "    # Convert all tokens in token_list to lowercase, remove non alfanumeric tokens and stem.\n",
    "    # Store the result in a new token list, clean_tokens.\n",
    "    # scode: filtered_tokens = <FILL IN>\n",
    "    filtered_tokens = [token.lower() for token in token_list if token.isalnum()]\n",
    "    \n",
    "    # Add art to corpus_filtered\n",
    "    # scode: <FILL IN>\n",
    "    corpus_filtered.append(filtered_tokens)\n",
    "\n",
    "print \"\\nLet's check the first tokens from document 0 after filtering:\"\n",
    "print corpus_filtered[0][0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Test.assertTrue(all([c==c.lower() for c in corpus_filtered[23]]), 'Capital letters have not been removed')\n",
    "Test.assertTrue(all([c.isalnum() for c in corpus_filtered[13]]), 'Non alphanumeric characters have not been removed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2. Stemming vs Lemmatization\n",
    "\n",
    "At this point, we can choose between applying a simple stemming or ussing lemmatization. We will try both to test their differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Apply the `.stem()` method, from the stemmer object created in the first line, to `corpus_filtered`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select stemmer.\n",
    "stemmer = nltk.stem.SnowballStemmer('english')\n",
    "corpus_stemmed = []\n",
    "\n",
    "for n, token_list in enumerate(corpus_filtered):\n",
    "    print \"\\rStemming article {0} out of {1}\".format(n + 1, n_art),\n",
    "    \n",
    "    # Convert all tokens in token_list to lowercase, remove non alfanumeric tokens and stem.\n",
    "    # Store the result in a new token list, clean_tokens.\n",
    "    # scode: stemmed_tokens = <FILL IN>\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in token_list]\n",
    "    \n",
    "    # Add art to the stemmed corpus\n",
    "    # scode: <FILL IN>\n",
    "    corpus_stemmed.append(stemmed_tokens)\n",
    "\n",
    "print \"\\nLet's check the first tokens from document 0 after stemming:\"\n",
    "print corpus_stemmed[0][0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Test.assertTrue((len([c for c in corpus_stemmed[0] if c!=stemmer.stem(c)]) < 0.1*len(corpus_stemmed[0])), \n",
    "                'It seems that stemming has not been applied properly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can apply lemmatization. For english texts, we can use the lemmatizer from NLTK, which is based on [WordNet](http://wordnet.princeton.edu). If you have not used wordnet before, you will likely need to download it from nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can comment this if the package is already available.\n",
    "# Select option \"d) Download\", and identifier \"wordnet\"\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Apply the `.lemmatize()` method, from the WordNetLemmatizer object created in the first line, to `corpus_filtered`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "# Select stemmer.\n",
    "corpus_lemmat = []\n",
    "\n",
    "for n, token_list in enumerate(corpus_filtered):\n",
    "    print \"\\rLemmatizing article {0} out of {1}\".format(n + 1, n_art),\n",
    "    \n",
    "    # scode: lemmat_tokens = <FILL IN>\n",
    "    lemmat_tokens = [wnl.lemmatize(token) for token in token_list]\n",
    "\n",
    "    # Add art to the stemmed corpus\n",
    "    # scode: <FILL IN>\n",
    "    corpus_lemmat.append(lemmat_tokens)\n",
    "\n",
    "print \"\\nLet's check the first tokens from document 0 after lemmatization:\"\n",
    "print corpus_lemmat[0][0:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the advantages of the lemmatizer method is that the result of lemmmatization is still a true word, which is more advisable for the presentation of text processing results and lemmatization.\n",
    "\n",
    "However, without using contextual information, lemmatize() does not remove grammatical differences. This is the reason why \"is\" or \"are\" are preserved and not replaced by infinitive \"be\".\n",
    "\n",
    "As an alternative, we can apply .lemmatize(word, pos), where 'pos' is a string code specifying the part-of-speech (pos), i.e. the grammatical role of the words in its sentence. For instance, you can check the difference between `wnl.lemmatize('is')` and `wnl.lemmatize('is, pos='v')`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Cleaning\n",
    "\n",
    "The third step consists of removing those words that are very common in language and do not carry out usefull semantic content (articles, pronouns, etc).\n",
    "\n",
    "Once again, we might need to load the stopword files using the download tools from `nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can comment this if the package is already available.\n",
    "# Select option \"d) Download\", and identifier \"stopwords\"\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Task**: In the second line below we read a list of common english stopwords. Clean `corpus_stemmed` by removing all tokens in the stopword list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_clean = []\n",
    "stopwords_en = stopwords.words('english')\n",
    "n = 0\n",
    "for token_list in corpus_stemmed:\n",
    "    n += 1\n",
    "    print \"\\rRemoving stopwords from article {0} out of {1}\".format(n, n_art),\n",
    "\n",
    "    # Remove all tokens in the stopwords list and append the result to corpus_clean\n",
    "    # scode: clean_tokens = <FILL IN>\n",
    "    clean_tokens = [token for token in token_list if token not in stopwords_en]    \n",
    "\n",
    "    # scode: <FILL IN>\n",
    "    corpus_clean.append(clean_tokens)\n",
    "    \n",
    "print \"\\n Let's check tokens after cleaning:\"\n",
    "print corpus_clean[0][0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Test.assertTrue(len(corpus_clean) == n_art, 'List corpus_clean does not contain the expected number of articles')\n",
    "Test.assertTrue(len([c for c in corpus_clean[0] if c in stopwords_en])==0, 'Stopwords have not been removed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Vectorization\n",
    "\n",
    "Up to this point, we have transformed the raw text collection of articles in a list of articles, where each article is a collection of the word roots that are most relevant for semantic analysis. Now, we need to convert these data (a list of token lists) into a numerical representation (a list of vectors, or a matrix). To do so, we will start using the tools provided by the `gensim` library. \n",
    "\n",
    "As a first step, we create a dictionary containing all tokens in our text corpus, and assigning an integer identifier to each one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create dictionary of tokens\n",
    "D = gensim.corpora.Dictionary(corpus_clean)\n",
    "n_tokens = len(D)\n",
    "\n",
    "print \"The dictionary contains {0} tokens\".format(n_tokens)\n",
    "print \"First tokens in the dictionary: \"\n",
    "for n in range(10):\n",
    "    print str(n) + \": \" + D[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second step, let us create a numerical version of our corpus using the `doc2bow` method. In general, `D.doc2bow(token_list)` transform any list of tokens into a list of tuples `(token_id, n)`, one per each token in `token_list`, where `token_id` is the token identifier (according to dictionary `D`) and `n` is the number of occurrences of such token in `token_list`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Task**: Apply the `doc2bow` method from gensim dictionary `D`, to all tokens in every article in `corpus_clean`. The result must be a new list named `corpus_bow` where each element is a list of tuples `(token_id, number_of_occurrences)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Transform token lists into sparse vectors on the D-space\n",
    "# scode: corpus_bow = <FILL IN>\n",
    "corpus_bow = [D.doc2bow(doc) for doc in corpus_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Test.assertTrue(len(corpus_bow)==n_art, 'corpus_bow has not the appropriate size') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, it is good to make sure to understand what has happened. In `corpus_clean` we had a list of token lists. With it, we have constructed a Dictionary, `D`, which assign an integer identifier to each token in the corpus.\n",
    "After that, we have transformed each article (in `corpus_clean`) in a list tuples `(id, n)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Original article (after cleaning): \"\n",
    "print corpus_clean[0][0:30]\n",
    "print \"Sparse vector representation (first 30 components):\"\n",
    "print corpus_bow[0][0:30]\n",
    "print \"The first component, {0} from document 0, states that token 0 ({1}) appears {2} times\".format(\n",
    "    corpus_bow[0][0], D[0], corpus_bow[0][0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can interpret each element of corpus_bow as a `sparse_vector`. For example, a list of tuples \n",
    "\n",
    "    [(0, 1), (3, 3), (5,2)] \n",
    "\n",
    "for a dictionary of 10 elements can be represented as a vector, where any tuple `(id, n)` states that position `id` must take value `n`. The rest of positions must be zero.\n",
    "\n",
    "    [1, 0, 0, 3, 0, 2, 0, 0, 0, 0]\n",
    "\n",
    "These sparse vectors will be the inputs to the topic modeling algorithms.\n",
    "\n",
    "Note that, at this point, we have built a Dictionary containing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"{0} tokens\".format(len(D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and a bow representation of a corpus with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"{0} Wikipedia articles\".format(len(corpus_bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting with the semantic analyisis, it is interesting to observe the token distribution for the given corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SORTED TOKEN FREQUENCIES (I):\n",
    "# Create a \"flat\" corpus with all tuples in a single list\n",
    "corpus_bow_flat = [item for sublist in corpus_bow for item in sublist]\n",
    "\n",
    "# Initialize a numpy array that we will use to count tokens.\n",
    "# token_count[n] should store the number of ocurrences of the n-th token, D[n]\n",
    "token_count = np.zeros(n_tokens)\n",
    "\n",
    "# Count the number of occurrences of each token.\n",
    "for x in corpus_bow_flat:\n",
    "    # Update the proper element in token_count\n",
    "    # scode: <FILL IN>\n",
    "    token_count[x[0]] += x[1]\n",
    "\n",
    "# Sort by decreasing number of occurences\n",
    "ids_sorted = np.argsort(- token_count)\n",
    "tf_sorted = token_count[ids_sorted]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ids_sorted` is a list of all token ids, sorted by decreasing number of occurrences in the whole corpus. For instance, the most frequent term is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print D[ids_sorted[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"{0} times in the whole corpus\".format(tf_sorted[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we plot the most frequent terms in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SORTED TOKEN FREQUENCIES (II):\n",
    "plt.rcdefaults()\n",
    "\n",
    "# Example data\n",
    "n_bins = 25\n",
    "hot_tokens = [D[i] for i in ids_sorted[n_bins-1::-1]]\n",
    "y_pos = np.arange(len(hot_tokens))\n",
    "z = tf_sorted[n_bins-1::-1]/n_art\n",
    "\n",
    "plt.barh(y_pos, z, align='center', alpha=0.4)\n",
    "plt.yticks(y_pos, hot_tokens)\n",
    "plt.xlabel('Average number of occurrences per article')\n",
    "plt.title('Token distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SORTED TOKEN FREQUENCIES:\n",
    "\n",
    "# Example data\n",
    "plt.semilogy(tf_sorted)\n",
    "plt.xlabel('Average number of occurrences per article')\n",
    "plt.title('Token distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exercise**: There are usually many tokens that appear with very low frequency in the corpus. Count the number of tokens appearing only once, and what is the proportion of them in the token list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scode: <WRITE YOUR CODE HERE>\n",
    "# Example data\n",
    "cold_tokens = [D[i] for i in ids_sorted if tf_sorted[i]==1]\n",
    "\n",
    "print \"There are {0} cold tokens, which represent {1}% of the total number of tokens in the dictionary\".format(\n",
    "    len(cold_tokens), float(len(cold_tokens))/n_tokens*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exercise**: Represent graphically those 20 tokens that appear in the highest number of articles. Note that you can use the code above (headed by `# SORTED TOKEN FREQUENCIES`) with a very minor modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scode: <WRITE YOUR CODE HERE>\n",
    "\n",
    "# SORTED TOKEN FREQUENCIES (I):\n",
    "# Count the number of occurrences of each token.\n",
    "token_count2 = np.zeros(n_tokens)\n",
    "for x in corpus_bow_flat:\n",
    "    token_count2[x[0]] += (x[1]>0)\n",
    "\n",
    "# Sort by decreasing number of occurences\n",
    "ids_sorted2 = np.argsort(- token_count2)\n",
    "tf_sorted2 = token_count2[ids_sorted2]\n",
    "\n",
    "# SORTED TOKEN FREQUENCIES (II):\n",
    "# Example data\n",
    "n_bins = 25\n",
    "hot_tokens2 = [D[i] for i in ids_sorted2[n_bins-1::-1]]\n",
    "y_pos2 = np.arange(len(hot_tokens2))\n",
    "z2 = tf_sorted2[n_bins-1::-1]/n_art\n",
    "\n",
    "plt.barh(y_pos2, z2, align='center', alpha=0.4)\n",
    "plt.yticks(y_pos2, hot_tokens2)\n",
    "plt.xlabel('Average number of occurrences per article')\n",
    "plt.title('Token distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exercise**: Count the number of tokens appearing only in a single article.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scode: <WRITE YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exercise** (*All in one*): Note that, for pedagogical reasons, we have used a different `for` loop for each text processing step creating a new `corpus_xxx` variable after each step. For very large corpus, this could cause memory problems. \n",
    "\n",
    "As a summary exercise, repeat the whole text processing, starting from corpus_text up to computing the bow, with the following modifications:\n",
    "\n",
    "1. Use a single `for` loop, avoiding the creation of any intermediate corpus variables.\n",
    "2. Use lemmatization instead of stemming.\n",
    "3. Remove all tokens appearing in only one document and less than 2 times.\n",
    "4. Save the result in a new variable `corpus_bow1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scode: <WRITE YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exercise** (*Visualizing categories*): Repeat the previous exercise with a second wikipedia category. For instance, you can take \"communication\". \n",
    "\n",
    "1. Save the result in variable `corpus_bow2`.\n",
    "2. Determine the most frequent terms in `corpus_bow1` (`term1`) and `corpus_bow2` (`term2`).\n",
    "3. Transform each article in `corpus_bow1` and `corpus_bow2` into a 2 dimensional vector, where the first component is the frecuency of `term1` and the second component is the frequency of `term2`\n",
    "4. Draw a dispersion plot of all 2 dimensional points, using a different marker for each corpus. Could you differentiate both corpora using the selected terms only? What if the 2nd most frequent term is used?\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scode: <WRITE YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exercise ** (bigrams): `nltk` provides an utility to compute n-grams from a list of tokens, in `nltk.util.ngrams`. Join all tokens in `corpus_clean` in a single list and compute the bigrams. Plot the 20 most frequent bigrams in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scode: <WRITE YOUR CODE HERE>\n",
    "# Check the code below to see how ngrams works, and adapt it to solve the exercise.\n",
    "# from nltk.util import ngrams\n",
    "# sentence = 'this is a foo bar sentences and i want to ngramize it'\n",
    "# sixgrams = ngrams(sentence.split(), 2)\n",
    "# for grams in sixgrams:\n",
    "#     print grams"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
